explanation of model choice:
Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) specifically designed to handle sequential data and long-term dependencies, making them highly effective for natural language processing tasks like sentiment analysis. LSTMs are particularly suited for cases where word order and contextual memory matter, such as movie reviews. We chose LSTM because it can learn temporal dynamics from sequences of word embeddings and provides strong performance on text classification tasks when trained on even moderately sized datasets. Although LSTMs do not match the speed or scale of transformer-based models like BERT, they offer a simpler and interpretable architecture that is well-suited for our 3,000-review training sample.

